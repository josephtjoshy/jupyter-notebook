{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "309df1398204c8c31b93dbca1fc64a902fef2e166c8721b4dfac039153d893cf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as sp\n",
    "from pyspark import SparkContext\n",
    "sc=SparkContext()\n",
    "spark=sp.sql.SparkSession.builder.master(\"local\").appName(\"testpipe\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=spark.read.csv('data.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+------------+-------------------+------+\n|firstName|    lastName|              email|salary|\n+---------+------------+-------------------+------+\n|   Basher|    armbrust|    bash@edureka.co|100000|\n|   Daniel|        meng|daniel@stanford.edu|120000|\n|   Muriel|        null|muriel@waterloo.edu|140000|\n|   Rachel|     wendell|  rach_3@edureka.co|160000|\n|     Zach|galifianakis|  zach_g@edureka.co|160000|\n+---------+------------+-------------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "\n",
    "Employee = Row(\"firstName\", \"lastName\", \"email\", \"salary\")\n",
    "\n",
    "employee1 = Employee('Basher', 'armbrust', 'bash@edureka.co', 100000)\n",
    "employee2 = Employee('Daniel', 'meng', 'daniel@stanford.edu', 120000 )\n",
    "employee3 = Employee('Muriel', None, 'muriel@waterloo.edu', 140000 )\n",
    "employee4 = Employee('Rachel', 'wendell', 'rach_3@edureka.co', 160000 )\n",
    "employee5 = Employee('Zach', 'galifianakis', 'zach_g@edureka.co', 160000 )\n",
    "\n",
    "dframe = spark.createDataFrame([employee1,employee2,employee3,employee4,employee5])\n",
    "dframe.select('*').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---+------------+\n| id|joining_date|\n+---+------------+\n| 10|  21-04-1998|\n| 20|  21-04-1998|\n| 30|  21-04-1998|\n| 45|  21-04-1998|\n| 50|  21-04-1998|\n| 60|  21-04-1998|\n| 70|  21-04-1998|\n| 25|  21-04-1998|\n| 26|  21-04-1998|\n| 35|  21-04-1998|\n|100|  21-04-1998|\n+---+------------+\n\n"
     ]
    }
   ],
   "source": [
    "date=Row('id','joining_date')\n",
    "\n",
    "\n",
    "date1=date(10,'21-04-1998')\n",
    "date2=date(20,'21-04-1998')\n",
    "date3=date(30,'21-04-1998')\n",
    "date4=date(45,'21-04-1998')\n",
    "date5=date(50,'21-04-1998')\n",
    "date6=date(60,'21-04-1998')\n",
    "date7=date(70,'21-04-1998')\n",
    "date8=date(25,'21-04-1998')\n",
    "date9=date(26,'21-04-1998')\n",
    "date10=date(35,'21-04-1998')\n",
    "date11=date(100,'21-04-1998')\n",
    "\n",
    "df =spark.createDataFrame([date1,date2,date3,date4,date5,date6,date7,date8,date9,date10,date11])\n",
    "df.select('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---+---+\n|  X|  Y|\n+---+---+\n| 10|1.0|\n| 20|2.0|\n| 30|3.0|\n| 45|4.2|\n| 50|5.2|\n+---+---+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "data.select('*').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined=data.join(df,df['id']==data['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---+----+---+------------+\n|  X|   Y| id|joining_date|\n+---+----+---+------------+\n| 10| 1.0| 10|  21-04-1998|\n| 20| 2.0| 20|  21-04-1998|\n| 30| 3.0| 30|  21-04-1998|\n| 45| 4.2| 45|  21-04-1998|\n| 50| 5.2| 50|  21-04-1998|\n| 60| 6.3| 60|  21-04-1998|\n| 70| 7.1| 70|  21-04-1998|\n| 25| 2.1| 25|  21-04-1998|\n| 26| 2.4| 26|  21-04-1998|\n| 35| 3.3| 35|  21-04-1998|\n|100|10.0|100|  21-04-1998|\n+---+----+---+------------+\n\n"
     ]
    }
   ],
   "source": [
    "joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- X: integer (nullable = true)\n |-- Y: double (nullable = true)\n |-- id: long (nullable = true)\n |-- joining_date: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "joined.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pand=joined.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pand.to_csv('datacheck.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}